{
  "dataset_reader": {
    "type": "my_seq2seq",
    "source_token_indexers": {
      "source_tokens": {
        "type": "single_id",
        "namespace": "source_tokens"
      },
      "openai": {
        "type": "openai_transformer_byte_pair",
        "model_path": "https://s3-us-west-2.amazonaws.com/allennlp/models/openai-transformer-lm-2018.07.23.tar.gz",
        "n_ctx": 150,
        "namespace": "openai_transformer"
      }
    },
    "target_token_indexers": {
      "tokens": {
        "type": "single_id",
        "namespace": "tokens"
      }
    },
    "source_tokenizer": {
      "type": "word",
      "word_splitter": {
        "type": "openai"
      }
    },
    "target_tokenizer": {
      "type": "word"
    }
  },
  "train_data_path": "data/atis/atis.train",
  "validation_data_path": "data/atis/atis.val",
  "model": {
    "type": "seq2seq",
    "source_embedder": {
      "source_tokens": {
        "type": "embedding",
        "vocab_namespace": "source_tokens",
        "embedding_dim": 100,
        "pretrained_file": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz",
        "trainable": true
      },
      "openai": {
        "type": "openai_transformer_embedder",
        "transformer": {
          "model_path": "https://s3-us-west-2.amazonaws.com/allennlp/models/openai-transformer-lm-2018.07.23.tar.gz",
          "n_ctx": "150"
        }
      },
      "embedder_to_indexer_map": {
        "openai": ["openai", "openai-offsets"],
        "source_tokens": ["source_tokens"]
      },
      "allow_unmatched_keys": true,
    },
    "encoder": {
      "type": "lstm",
      "input_size": 868,
      "hidden_size": 200,
      "num_layers": 1,
      "bidirectional": true
    },
    "attention": {
      "type": "bilinear",
      "vector_dim": 400,
      "matrix_dim": 400
    },
    "target_embedding_dim": 100,
    "target_namespace": "tokens",
    "beam_size": 5,
    "max_decoding_steps": 100,
    "use_bleu": true
  },
  "iterator": {
    "type": "bucket",
    "padding_noise": 0.0,
    "batch_size" : 16,
    "sorting_keys": [["target_tokens", "num_tokens"]]
  },
  "trainer": {
    "optimizer": {
      "type": "adam",
      "lr": 0.01
    },
    "learning_rate_scheduler": {
      "type": "noam",
      "warmup_steps": 1000,
      "model_size": 200
    },
    "num_epochs": 150,
    "patience" : 30,
    "cuda_device": 1,
    "should_log_learning_rate": true,
    "should_log_parameter_statistics": false,
    "validation_metric": "+seq_acc"
  }
}
